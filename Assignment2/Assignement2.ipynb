{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    #Assignment 2 \n",
    "- 1D 2 class Gaussian Discriminent\n",
    "- 2D 2 class Gaussian Discriminent\n",
    "- kD k class Gaussian Discriminent\n",
    "### setting all the imports\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# all imports\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.cross_validation import KFold    \n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import inv\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import datasets\n",
    "import collections # this is used to perform the collection  based sorting  and unique element identification\n",
    "from sklearn.cross_validation import train_test_split #  this is used for cross validation \n",
    "from functools import partial # this is to accomdate partials\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are using the iris data from  the first three questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fetching all data\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "numberOfClass = lambda listValues :list(set(listValues))# this is the number of classes in each dataset\n",
    "\n",
    "m = lambda listValues: collections.Counter(listValues)\n",
    "\n",
    "idf = lambda currentClass,itratingClass : (0,1)[currentClass == itratingClass] # this is the indicator function\n",
    "\n",
    "mean = lambda X_D,Y_D:[np.mean([idf(Y_D[rowIndex],classElement)*rowElements for rowIndex,rowElements in enumerate(X_D)if idf(Y_D[rowIndex],classElement)== 1],0) for classIndex ,classElement in enumerate(numberOfClass(Y_D))]\n",
    "\n",
    "varience =lambda X_D,Y_D:[np.var([idf(Y_D[rowIndex],classElement)*rowElements for rowIndex,rowElements in enumerate(X_D)if idf(Y_D[rowIndex],classElement)== 1],0) for classIndex ,classElement in enumerate(numberOfClass(Y_D))]\n",
    "\n",
    "alpha = lambda X_D,Y_D:[m(Y_1D)[classElement]*1.0/len(Y_D) for classElement in (numberOfClass(Y_D))]\n",
    "\n",
    "g = lambda x,var,mean,alpha: np.log2(alpha)- (((x-mean)**2)/2*(var**2))\n",
    "\n",
    "def discriminent (x,a_class,b_class):\n",
    "    if a_class(x)>b_class(x):\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TestMetrics:\n",
    "    \n",
    "    def setData(self,y_test,y_pred_class):\n",
    "            self.y_test = y_test\n",
    "            self.y_pred_class = y_pred_class\n",
    "#             print 'True:', y_test\n",
    "#             print 'Pred:', y_pred_class\n",
    "        \n",
    "    def getMatrics(self):\n",
    "        print metrics.accuracy_score(self.y_test, self.y_pred_class)\n",
    "        # save confusion matrix and slice into four pieces\n",
    "        confusion = metrics.confusion_matrix(self.y_test, self.y_pred_class)\n",
    "        print \"confusion matrix:\",confusion\n",
    "        TP = confusion[1, 1]\n",
    "        TN = confusion[0, 0]\n",
    "        FP = confusion[0, 1]\n",
    "        FN = confusion[1, 0]\n",
    "        \n",
    "        #Classification Accuracy: Overall, how often is the classifier correct?\n",
    "        Classification_Accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "        print \"#Classification Accuracy:\\t\",Classification_Accuracy\n",
    "        # print metrics.accuracy_score(y_test, y_pred_class)\n",
    "        \n",
    "        #Classification Error: Overall, how often is the classifier incorrect?\n",
    "        Classification_Error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "        print \"#Classification Error:\\t\",Classification_Error\n",
    "        #print 1 - metrics.accuracy_score(y_test, y_pred_class)\n",
    "        \n",
    "        #Sensitivity:\n",
    "        Sensitivity = TP / float(TP + FN)\n",
    "        print \"#Sensitivity:\\t\",Sensitivity\n",
    "        #print metrics.recall_score(y_test, y_pred_class)\n",
    "        #Specificity: \n",
    "        Specificity = TN / float(TN + FP)\n",
    "        print \"#Specificity:\\t\",Specificity\n",
    "        #False Positive Rate:\n",
    "        False_Positive_Rate = FP / float(TN + FP)\n",
    "        print \"#False Positive Rate:\",False_Positive_Rate\n",
    "        #Precision: \n",
    "        Precision = TP / float(TP + FP)\n",
    "        print \"#Precision:\\t\",Precision\n",
    "        #print metrics.precision_score(y_test, y_pred_class)\n",
    "        print TP,TN,FP,FN,Classification_Accuracy,Classification_Error,Sensitivity,Specificity,False_Positive_Rate,Precision\n",
    "        return TP,TN,FP,FN,Classification_Accuracy,Classification_Error,Sensitivity,Specificity,False_Positive_Rate,Precision\n",
    "#test        \n",
    "# tm  = TestMetrics()\n",
    "# tm.setData(Y,Y)\n",
    "# tm.getMatrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GDA1D2C:\n",
    "    #this si to fit the existing data\n",
    "    def fit(self,Xdata,Ydata):\n",
    "        self.XData = Xdata\n",
    "        self.YData = Ydata\n",
    "        #step:1 - find alpha\n",
    "        self.alpha = alpha(Xdata,Ydata)\n",
    "#         print \"alpha\"\n",
    "#         print self.alpha\n",
    "        #step:2 - find mean \n",
    "        self.mean = mean(Xdata,Ydata)\n",
    "#         print \"mean\"\n",
    "#         print self.mean\n",
    "        #step:3 - find varience\n",
    "        self.varience = varience(Xdata,Ydata)\n",
    "#         print\"varience\"\n",
    "#         print self.varience\n",
    "        #step:4\n",
    "        g0 = partial(g,var = self.varience[0],mean= self.mean[0],alpha= self.alpha[0])\n",
    "        g1 = partial(g,var = self.varience[1],mean= self.mean[1],alpha= self.alpha[1])\n",
    "        #step:5\n",
    "        self.discriminent = partial(discriminent,a_class = g0, b_class = g1)\n",
    "        #self.discriminent = partial(discriminent,a_class = partial(g,varience = self.varience[0],mean= self.mean[0],alpha= self.alpha[0]), b_class = partial(g,varience = self.varience[1],mean= self.mean[1],alpha= self.alpha[1]))\n",
    "    # this is to predict y data  from the give X data\n",
    "    def predict(self,XD):\n",
    "        return [self.discriminent(xvalue) for xvalue in XD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy  Error  FN  FP  False_Positive_Rate  Precision  Sensitivity  \\\n",
      "0       0.2    0.8   9  23                 0.92   0.206897          0.4   \n",
      "1       0.2    0.8   9  23                 0.92   0.206897          0.4   \n",
      "2       0.2    0.8   9  23                 0.92   0.206897          0.4   \n",
      "3       0.2    0.8   9  23                 0.92   0.206897          0.4   \n",
      "4       0.2    0.8   9  23                 0.92   0.206897          0.4   \n",
      "\n",
      "   Specificity  TN  TP  \n",
      "0         0.08   2   6  \n",
      "1         0.08   2   6  \n",
      "2         0.08   2   6  \n",
      "3         0.08   2   6  \n",
      "4         0.08   2   6  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_1D = X[:100,:1]# this is to take one feature and first 100 data sets\n",
    "Y_1D = Y [:100] # this is to take 1st 100 data sets\n",
    "\n",
    "#print np.sum(X_12)/50\n",
    "#print Y_1D.size\n",
    "# print X_1D\n",
    "# print Y_1D\n",
    "# print len(X_1D)\n",
    "# print alpha(X_1D,Y_1D)\n",
    "# print mean(X_1D,Y_1D)\n",
    "# print varience(X_1D,Y_1D)[0]\n",
    "# STEP 1: split X and y into training and testing set\n",
    "matricsTotal = []\n",
    "kf = sklearn.cross_validation.KFold(n=len(Y_1D), n_folds=5, shuffle=True,random_state=None)\n",
    "for train_index, test_index in kf:\n",
    "    #print train_index\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(X_1D, Y_1D, test_size=0.4, random_state= a)\n",
    "    X_train, X_test =[list(X_1D[a]) for a  in train_index],[list(X_1D[a]) for a  in test_index]\n",
    "    Y_train, Y_test = [Y_1D[a] for a  in train_index],[Y_1D[a] for a  in test_index]\n",
    "#     print X_train\n",
    "#     #     print Y_train\n",
    "#     print \"\\n\\n\"\n",
    "    grad =  GDA1D2C()\n",
    "    grad.fit(X_train,Y_train)\n",
    "    predicted_Y_values = grad.predict(X_test)\n",
    "    tm  = TestMetrics()\n",
    "    tm.setData(Y_test,predicted_Y_values)\n",
    "    TP,TN,FP,FN,Classification_Accuracy,Classification_Error,Sensitivity,Specificity,False_Positive_Rate,Precision\n",
    "    matricsTotal.append({\"TP\":TP,\"TN\":TN,\"FP\":FP,\"FN\":FN,\"Accuracy\":Classification_Accuracy,\"Error\":Classification_Error,\"Sensitivity\":Sensitivity,\"Specificity\":Specificity,\"False_Positive_Rate\":False_Positive_Rate,\"Precision\":Precision})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(matricsTotal)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
